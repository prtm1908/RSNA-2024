{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumbarSpineDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.levels = ['L1_L2', 'L2_L3', 'L3_L4', 'L4_L5', 'L5_S1']\n",
    "        self.conditions = ['spinal_canal_stenosis', 'left_neural_foraminal_narrowing', \n",
    "                           'right_neural_foraminal_narrowing', 'left_subarticular_stenosis', \n",
    "                           'right_subarticular_stenosis']\n",
    "        self.valid_indices = self._get_valid_indices()\n",
    "        \n",
    "    def _get_valid_indices(self):\n",
    "        valid_indices = []\n",
    "        for idx, row in self.data.iterrows():\n",
    "            study_id = str(row['study_id'])\n",
    "            study_folder = os.path.join(self.img_dir, study_id)\n",
    "            if not os.path.exists(study_folder):\n",
    "                continue\n",
    "            subfolders = [f for f in os.listdir(study_folder) if os.path.isdir(os.path.join(study_folder, f))]\n",
    "            if not subfolders:\n",
    "                continue\n",
    "            subfolder = subfolders[0]\n",
    "            if all(os.path.exists(os.path.join(study_folder, subfolder, f\"{level}.png\")) for level in self.levels):\n",
    "                valid_indices.append(idx)\n",
    "        return valid_indices\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.valid_indices[idx]\n",
    "        study_id = str(self.data.iloc[real_idx]['study_id'])\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        study_folder = os.path.join(self.img_dir, study_id)\n",
    "        subfolders = [f for f in os.listdir(study_folder) if os.path.isdir(os.path.join(study_folder, f))]\n",
    "        subfolder = subfolders[0]  # Assume there's only one subfolder\n",
    "        \n",
    "        for level in self.levels:\n",
    "            img_path = os.path.join(study_folder, subfolder, f\"{level}.png\")\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            images.append(image)\n",
    "            \n",
    "            level_labels = []\n",
    "            for condition in self.conditions:\n",
    "                col_name = f\"{condition}_{level.lower()}\"\n",
    "                severity = self.data.iloc[real_idx][col_name]\n",
    "                label = torch.zeros(3)\n",
    "                if severity == 'Normal/Mild':\n",
    "                    label[0] = 1\n",
    "                elif severity == 'Moderate':\n",
    "                    label[1] = 1\n",
    "                elif severity == 'Severe':\n",
    "                    label[2] = 1\n",
    "                level_labels.extend(label)\n",
    "            labels.extend(level_labels)\n",
    "        \n",
    "        return images, torch.tensor(labels)\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset and data loader\n",
    "train_dataset = LumbarSpineDataset('data/train.csv', 'crops224', transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LumbarSpineModel(nn.Module):\n",
    "    def __init__(self, num_classes=75):  # 5 levels * 5 conditions * 3 severities\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model('maxvit_tiny_tf_224.in1k', pretrained=True, num_classes=0)\n",
    "\n",
    "        # Get the number of output features from the backbone\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            features = self.backbone(dummy_input)\n",
    "            num_features = features.shape[1]\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(num_features * 5, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, list):\n",
    "            # If x is a list of tensors (one for each image)\n",
    "            features = []\n",
    "            for i, img in enumerate(x):\n",
    "                feat = self.backbone(img)\n",
    "                features.append(feat)\n",
    "            combined_features = torch.cat(features, dim=1)\n",
    "        else:\n",
    "            # If x is a single tensor of shape (batch_size, 5, 3, H, W)\n",
    "            batch_size, num_images, C, H, W = x.shape\n",
    "            x = x.view(batch_size * num_images, C, H, W)\n",
    "            features = self.backbone(x)\n",
    "            combined_features = features.view(batch_size, -1)\n",
    "        \n",
    "        x = self.dropout(combined_features)\n",
    "        return self.fc(combined_features)\n",
    "\n",
    "model = LumbarSpineModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_bce_loss(predictions, targets, pos_weights):\n",
    "    return F.binary_cross_entropy_with_logits(predictions, targets, pos_weight=pos_weights)\n",
    "\n",
    "# Define pos_weights based on severity levels\n",
    "pos_weights = torch.tensor([1.0, 2.0, 4.0]).repeat(25).to(device)  # 25 = 5 levels * 5 conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "Train Loss: 0.4831\n",
      "Train Weighted Log Loss: 18.7591\n",
      "Validation Loss: 0.4447\n",
      "Validation Weighted Log Loss: 16.0321\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:\n",
      "Train Loss: 0.4052\n",
      "Train Weighted Log Loss: 15.6060\n",
      "Validation Loss: 0.4241\n",
      "Validation Weighted Log Loss: 16.1417\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:\n",
      "Train Loss: 0.3733\n",
      "Train Weighted Log Loss: 14.2439\n",
      "Validation Loss: 0.4249\n",
      "Validation Weighted Log Loss: 16.8188\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50:\n",
      "Train Loss: 0.3400\n",
      "Train Weighted Log Loss: 12.8922\n",
      "Validation Loss: 0.4166\n",
      "Validation Weighted Log Loss: 16.9980\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:\n",
      "Train Loss: 0.2999\n",
      "Train Weighted Log Loss: 11.1046\n",
      "Validation Loss: 0.4256\n",
      "Validation Weighted Log Loss: 17.7534\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:\n",
      "Train Loss: 0.2572\n",
      "Train Weighted Log Loss: 9.3945\n",
      "Validation Loss: 0.4373\n",
      "Validation Weighted Log Loss: 19.2279\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50:\n",
      "Train Loss: 0.2154\n",
      "Train Weighted Log Loss: 7.7843\n",
      "Validation Loss: 0.4510\n",
      "Validation Weighted Log Loss: 20.4508\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50:\n",
      "Train Loss: 0.1642\n",
      "Train Weighted Log Loss: 5.8250\n",
      "Validation Loss: 0.4714\n",
      "Validation Weighted Log Loss: 22.2791\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50:\n",
      "Train Loss: 0.1303\n",
      "Train Weighted Log Loss: 4.5781\n",
      "Validation Loss: 0.4710\n",
      "Validation Weighted Log Loss: 21.8398\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50:\n",
      "Train Loss: 0.1048\n",
      "Train Weighted Log Loss: 3.6522\n",
      "Validation Loss: 0.5050\n",
      "Validation Weighted Log Loss: 24.5458\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m weighted_bce_loss(output, target, pos_weights)\n\u001b[0;32m---> 45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     46\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    523\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m _engine_run_backward(\n\u001b[1;32m    290\u001b[0m     tensors,\n\u001b[1;32m    291\u001b[0m     grad_tensors_,\n\u001b[1;32m    292\u001b[0m     retain_graph,\n\u001b[1;32m    293\u001b[0m     create_graph,\n\u001b[1;32m    294\u001b[0m     inputs,\n\u001b[1;32m    295\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    296\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    297\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    769\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    770\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def weighted_log_loss(y_true, y_pred, weights=[1, 2, 4]):\n",
    "    \"\"\"\n",
    "    Calculate weighted log loss\n",
    "    \"\"\"\n",
    "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "    loss = 0\n",
    "    for i in range(0, y_true.shape[1], 3):\n",
    "        loss += np.sum(weights * (y_true[:, i:i+3] * np.log(y_pred[:, i:i+3])))\n",
    "    return -loss / y_true.shape[0]\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "train_indices, val_indices = train_test_split(range(len(train_dataset)), test_size=0.2, random_state=42)\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, sampler=train_sampler, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, sampler=val_sampler, num_workers=4)\n",
    "\n",
    "model = LumbarSpineModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_weighted_log_loss = 0\n",
    "    train_batches = 0\n",
    "\n",
    "    # Training loop with tqdm\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]', leave=False)\n",
    "    for data, target in train_pbar:\n",
    "        try:\n",
    "            data = [img.to(device) for img in data]\n",
    "            target = target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = weighted_bce_loss(output, target, pos_weights)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_weighted_log_loss += weighted_log_loss(target.cpu().numpy(), torch.sigmoid(output).detach().cpu().numpy())\n",
    "            train_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({'Loss': f'{train_loss/train_batches:.4f}', 'WLogLoss': f'{train_weighted_log_loss/train_batches:.4f}'})\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {str(e)}\")\n",
    "            print(f\"Data shapes: {[img.shape for img in data]}\")\n",
    "            print(f\"Target shape: {target.shape}\")\n",
    "            print(f\"Model structure: {model}\")\n",
    "            raise e\n",
    "        \n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_weighted_log_loss = 0\n",
    "    val_batches = 0\n",
    "\n",
    "    # Validation loop with tqdm\n",
    "    val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]', leave=False)\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_pbar:\n",
    "            data = [img.to(device) for img in data]\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = weighted_bce_loss(output, target, pos_weights)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_weighted_log_loss += weighted_log_loss(target.cpu().numpy(), torch.sigmoid(output).cpu().numpy())\n",
    "            val_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            val_pbar.set_postfix({'Loss': f'{val_loss/val_batches:.4f}', 'WLogLoss': f'{val_weighted_log_loss/val_batches:.4f}'})\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {train_loss/train_batches:.4f}')\n",
    "    print(f'Train Weighted Log Loss: {train_weighted_log_loss/train_batches:.4f}')\n",
    "    print(f'Validation Loss: {val_loss/val_batches:.4f}')\n",
    "    print(f'Validation Weighted Log Loss: {val_weighted_log_loss/val_batches:.4f}')\n",
    "    print('-' * 50)\n",
    "\n",
    "    scheduler.step(val_weighted_log_loss/val_batches)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_weighted_log_loss/val_batches < best_val_loss:\n",
    "        best_val_loss = val_weighted_log_loss/val_batches\n",
    "        patience_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_lumbar_spine_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Save the final model\n",
    "torch.save(model.state_dict(), 'lumbar_spine_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, test_loader, submission_file):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = [img.to(device) for img in data]\n",
    "            output = model(data)\n",
    "            probs = torch.sigmoid(output).cpu().numpy()\n",
    "            predictions.append(probs)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission = pd.read_csv('sample_submission.csv')\n",
    "    submission.iloc[:, 1:] = predictions\n",
    "    \n",
    "    # Ensure probabilities sum to 1 for each condition\n",
    "    for i in range(0, submission.shape[1] - 1, 3):\n",
    "        submission.iloc[:, i+1:i+4] = submission.iloc[:, i+1:i+4].div(submission.iloc[:, i+1:i+4].sum(axis=1), axis=0)\n",
    "    \n",
    "    submission.to_csv(submission_file, index=False)\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = LumbarSpineDataset('test.csv', 'test_images', transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the trained model\n",
    "model = LumbarSpineModel().to(device)\n",
    "model.load_state_dict(torch.load('lumbar_spine_model.pth'))\n",
    "\n",
    "# Generate submission\n",
    "generate_submission(model, test_loader, 'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
